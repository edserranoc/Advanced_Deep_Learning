{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<div style=\"background-color: lightgray; padding: 20px; color: black;\">\n",
    "<div>\n",
    "<img src=\"https://th.bing.com/th/id/R.3cd1c8dc996c5616cf6e65e20b6bf586?rik=09aaLyk4hfbBiQ&riu=http%3a%2f%2fcidics.uanl.mx%2fwp-content%2fuploads%2f2016%2f09%2fcimat.png&ehk=%2b0brgMUkA2BND22ixwLZheQrrOoYLO3o5cMRqsBOrlY%3d&risl=&pid=ImgRaw&r=0\" style=\"float: right; margin-right: 30px;\" width=\"200\"/> \n",
    "<font size=\"5.5\" color=\"8C3061\"><b>Only-Encoder Transformer y Fine-Tunning para predicción de series temporales </b></font> <br>\n",
    "<font size=\"4.5\" color=\"8C3061\"><b>Aprendizaje de Máquina II - Tarea 2 </b></font> \n",
    "</div>\n",
    "<div style=\"text-align: left\">  <br>\n",
    "Edison David Serrano Cárdenas. <br>\n",
    "MSc en Matemáticas Aplicadas <br>\n",
    "CIMAT - Sede Guanajuato <br>\n",
    "</div>\n",
    "\n",
    "</div>\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"8C3061\" >**Cargar Librerías**</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load basic libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Load libraries for data processing\n",
    "from generate_data import GenerateData as gd\n",
    "from only_encoder_transformer import ForecastingModel\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "import torch\n",
    "\n",
    "# Load libraries for model evaluation\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Load libraries for plotting\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Verificación de CUDA, Fijar la Semilla**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device is: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"device is:\",device)\n",
    "\n",
    "SEED = 42\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"8C3061\" >**Enunciado del problema**</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considere el valor histórico por hora de una base de datos de tipo de cambio  monedas y precio diario en dólares (USD) del petroleo, obtenga N series de al menos una longitud de T = 100. \n",
    "\n",
    "Luego entrene un modelo usando un OnlyEncoder Transformer y realizando Full-FineTuning y LoRA tuning para que dadas las series S[:T-t] prediga la parte final de cada serie S[T-t:]. Un valor típico es t=5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"8C3061\" >**Preprocesamiento de los Datos**</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descarga de los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing data from data/crypto_data.csv\n",
      "Loading existing data from data/exchange_oil_data.csv\n"
     ]
    }
   ],
   "source": [
    "crypto_data = gd.download_crypto_data()\n",
    "exchange_data = gd.download_exchange_and_oil_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parámetros para la generación de los datos: \n",
    "\n",
    "Se elige un BATCH_SIZE = 32 y type_normalization = MinMaxScaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cryptos = ['BTC-USD', 'ETH-USD', 'BNB-USD', 'XRP-USD', 'ADA-USD', 'SOL-USD', 'DOGE-USD']\n",
    "currencies = ['EUR','JPY', 'GBP', 'AUD', 'CAD','HKD', 'MXN','COP']\n",
    "oil_ticker = 'CL=F'\n",
    "period = '1mo'\n",
    "interval = '1h'\n",
    "folder_name = 'data'\n",
    "file_name = 'exchange_oil_data'\n",
    "type_normalization = \"MinMaxScaler\"\n",
    "test_size = 0.2\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Nota:</b> Los datos se generaron bajo las instrucciones del script <i><b> generate_data.py</b></i>. Los datos se generaron una vez y se guardaron en la carpeta <i><b>data</b></i>, si se quiere usar otro tipo de cripto monedas o tasas de cambio, se debe eliminar la carpeta. </div>\n",
    "\n",
    "\n",
    "Generación de los datos:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing data from data/exchange_oil_data.csv\n",
      "Loading existing data from data/exchange_oil_data.csv\n"
     ]
    }
   ],
   "source": [
    "train_loader_crypto, test_loader_crypto, train_loader_exchange, test_loader_exchange, scalers_cd, scalers_ed  = gd.generate_data(cryptos = cryptos,\n",
    "                                                                                                        currencies = currencies,\n",
    "                                                                                                        oil_ticker = oil_ticker,\n",
    "                                                                                                        period = period,\n",
    "                                                                                                        interval = interval,\n",
    "                                                                                                        folder_name = folder_name,\n",
    "                                                                                                        file_name = file_name,\n",
    "                                                                                                        type_normalization = type_normalization,\n",
    "                                                                                                        test_size = test_size,\n",
    "                                                                                                        batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"8C3061\" >**Entrenamiento del Modelo**</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamiento de los modelos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función de entrenamiento\n",
    "def train_only_encoder(model, dataloader, optimizer, criterion, num_epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        for x_batch, y_batch in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Convertir los datos a float32 y enviarlos al dispositivo\n",
    "            x_batch = x_batch.to(device).float()\n",
    "            y_batch = y_batch.to(device).float()\n",
    "            \n",
    "            # Forward pass\n",
    "            output = model(x=x_batch)\n",
    "            \n",
    "            # Calcular la pérdida\n",
    "            loss = criterion(output, y_batch)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # Backward pass y optimización\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(dataloader)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluación del rendimiento de los modelos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_evaluation(model, test_loader,name_model = None):\n",
    "    predicted_close_values = []\n",
    "    true_close_values = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in test_loader:\n",
    "            x_batch = x_batch.to(device).float()\n",
    "            y_batch = y_batch.to(device).float()\n",
    "            \n",
    "            output = model(x= x_batch)\n",
    "            \n",
    "            predicted_close_values.extend(output.cpu().numpy())\n",
    "            true_close_values.extend(y_batch.cpu().numpy())\n",
    "            \n",
    "    true_close_values = np.array(true_close_values)\n",
    "    predicted_close_values = np.array(predicted_close_values)\n",
    "    \n",
    "    mse = mean_squared_error(true_close_values, predicted_close_values)\n",
    "    mae = mean_absolute_error(true_close_values, predicted_close_values)\n",
    "    r2 = r2_score(true_close_values, predicted_close_values)\n",
    "    \n",
    "    return mse, mae, r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardar los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "def save_model(model, name_model):\n",
    "    if not os.path.exists('models'):\n",
    "        os.makedirs('models')\n",
    "    \n",
    "    model_path = f'models/{name_model}.pth'\n",
    "    \n",
    "    if os.path.exists(model_path):\n",
    "        print(f\"The model {name_model} already exists\")\n",
    "    else:\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        print(f\"Model {name_model} saved successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargar modelos guardados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model, name_model):\n",
    "    model.load_state_dict(torch.load(f'models/{name_model}.pth',weights_only=True))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contar los parámetros entrenables del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_trainable_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definición de los hiperpárametros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "d_model = 64\n",
    "nhead = 4\n",
    "num_encoder_layers = 3\n",
    "dim_feedforward =  2048\n",
    "dropout = 0.1 \n",
    "\n",
    "# create a score dataframe\n",
    "score = pd.DataFrame(columns=[\"Model\",\"MSE\",\"MAE\",\"R2\",\"Trainable Parameters\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"8C3061\" >**Modelo OnlyEncoder**</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"8C3061\" >**Modelo Entrenado Desde Cero (Cambio de Moneda)**</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.04294068758775081\n",
      "Epoch 2/10, Loss: 0.02530731393822602\n",
      "Epoch 3/10, Loss: 0.014574544221561934\n",
      "Epoch 4/10, Loss: 0.012691771412002189\n",
      "Epoch 5/10, Loss: 0.010260386009966689\n",
      "Epoch 6/10, Loss: 0.010950134568182486\n",
      "Epoch 7/10, Loss: 0.008585814752482943\n",
      "Epoch 8/10, Loss: 0.008049559363696192\n",
      "Epoch 9/10, Loss: 0.008377493991117393\n",
      "Epoch 10/10, Loss: 0.007347668388060161\n"
     ]
    }
   ],
   "source": [
    "only_encoder_model_exchange = ForecastingModel(seq_len=95,\n",
    "                                               pred_len=5,\n",
    "                                               embed_size=d_model,\n",
    "                                               nhead=nhead,\n",
    "                                               dim_feedforward=dim_feedforward,\n",
    "                                               dropout=dropout,\n",
    "                                               conv1d_emb=True,\n",
    "                                               conv1d_kernel_size=3,\n",
    "                                               device=device).to(device)\n",
    "\n",
    "criterion_ex = torch.nn.MSELoss()\n",
    "optimizer_ex = torch.optim.Adam(only_encoder_model_exchange.parameters(), lr=0.0001)\n",
    "\n",
    "train_only_encoder(only_encoder_model_exchange, train_loader_exchange, optimizer_ex, criterion_ex, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only Encoder Exchange score:\n",
      "MSE: 0.009579326957464218\n",
      "MAE: 0.07404439896345139\n",
      "R2: 0.8826397657394409\n",
      "Trainable Parameters: 15,923,909\n"
     ]
    }
   ],
   "source": [
    "mse, mae, r2 = test_evaluation(only_encoder_model_exchange, test_loader_exchange)\n",
    "num_par = count_trainable_parameters(only_encoder_model_exchange)\n",
    "score.loc[0] = [\"Only Encoder Exchange\", mse, mae, r2, num_par]\n",
    "print(\"Only Encoder Exchange score:\\nMSE: {}\\nMAE: {}\\nR2: {}\".format(mse, mae, r2))\n",
    "print(\"Trainable Parameters: {:,}\".format(num_par))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"8C3061\" >**Modelo Entrenado Desde Cero (Cryptos)**</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.040095917148781676\n",
      "Epoch 2/10, Loss: 0.020898833804364716\n",
      "Epoch 3/10, Loss: 0.013555606993447458\n",
      "Epoch 4/10, Loss: 0.012641879813080388\n",
      "Epoch 5/10, Loss: 0.009917656159294503\n",
      "Epoch 6/10, Loss: 0.008835517418836909\n",
      "Epoch 7/10, Loss: 0.00865155687954809\n",
      "Epoch 8/10, Loss: 0.008441472692149026\n",
      "Epoch 9/10, Loss: 0.007273379347420165\n",
      "Epoch 10/10, Loss: 0.007354637308578406\n"
     ]
    }
   ],
   "source": [
    "only_encoder_model_crypto = ForecastingModel(seq_len=95,\n",
    "                                            pred_len=5,\n",
    "                                            embed_size=d_model,\n",
    "                                            nhead=nhead,\n",
    "                                            dim_feedforward=dim_feedforward,\n",
    "                                            dropout=dropout,\n",
    "                                            conv1d_emb=True,\n",
    "                                            conv1d_kernel_size=3,\n",
    "                                            device=device).to(device)\n",
    "\n",
    "criterion_cr = torch.nn.MSELoss()\n",
    "optimizer_cr = torch.optim.Adam(only_encoder_model_crypto.parameters(), lr=0.0001)\n",
    "\n",
    "train_only_encoder(only_encoder_model_crypto, train_loader_crypto, optimizer_cr, criterion_cr, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only Encoder Crypto score:\n",
      "MSE: 0.009489606134593487\n",
      "MAE: 0.07232800126075745\n",
      "R2: 0.8836885690689087\n",
      "Trainable Parameters:  15923909\n"
     ]
    }
   ],
   "source": [
    "mse, mae, r2 = test_evaluation(only_encoder_model_crypto, test_loader_crypto)\n",
    "num_par = count_trainable_parameters(only_encoder_model_crypto)\n",
    "score.loc[1] = [\"Only Encoder Crypto\", mse, mae, r2, num_par]\n",
    "print(\"Only Encoder Crypto score:\\nMSE: {}\\nMAE: {}\\nR2: {}\".format(mse, mae, r2))\n",
    "print(\"Trainable Parameters: \", num_par)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model only_encoder_model_exchange already exists\n",
      "The model only_encoder_model_crypto already exists\n"
     ]
    }
   ],
   "source": [
    "save_model(only_encoder_model_exchange, \"only_encoder_model_exchange\")\n",
    "save_model(only_encoder_model_crypto, \"only_encoder_model_crypto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"8C3061\" >**Fine Tunning**</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creación de los Modelos LoRA bajo diferentes parámetros $r$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoRAModel(r = 1, epochs = 2):\n",
    "    load_model_Lora = ForecastingModel(seq_len=95,\n",
    "                                        pred_len=5,\n",
    "                                        embed_size=d_model,\n",
    "                                        nhead=nhead,\n",
    "                                        dim_feedforward=dim_feedforward,\n",
    "                                        dropout=dropout,\n",
    "                                        conv1d_emb=True,\n",
    "                                        conv1d_kernel_size=3,\n",
    "                                        device=device).to(device)\n",
    "    \n",
    "    load_model_Lora = load_model(load_model_Lora, \"only_encoder_model_crypto\")\n",
    "    print(\"Total parameters before fine-tuning:\\t{:,.0f}\".format(count_trainable_parameters(load_model_Lora)))\n",
    "    \n",
    "    # Define the LoRA configuration\n",
    "    lora_config = LoraConfig(\n",
    "        task_type=TaskType.FEATURE_EXTRACTION,  # Use TASK for regression\n",
    "        r=r,  # Adjust this based on your needs\n",
    "        lora_alpha=32,  # Scaling factor\n",
    "        lora_dropout=0.1,  # Dropout for LoRA layers\n",
    "        target_modules=[\n",
    "            \"self_attn.in_proj_weight\", \n",
    "            \"self_attn.out_proj\",\n",
    "            \"linear1\", \n",
    "            \"linear2\"\n",
    "        ]  # Ensure these modules are appropriate for your model\n",
    "    )\n",
    "    \n",
    "    lora_model = get_peft_model(load_model_Lora, lora_config)\n",
    "    print(\"Total parameters after fine-tuning:\\t{:,.0f}\\n\\n\".format(count_trainable_parameters(lora_model)))\n",
    "    \n",
    "    # Define the loss function and optimizer\n",
    "    criterion_lora1 = torch.nn.MSELoss()\n",
    "    optimizer_lora1 = torch.optim.Adam(filter(lambda p: p.requires_grad, lora_model.parameters()), lr=0.0001)\n",
    "    \n",
    "    # Fine-tune the model for 2 epochs\n",
    "    train_only_encoder(model=lora_model, \n",
    "                        dataloader=train_loader_crypto, \n",
    "                        optimizer=optimizer_lora1, \n",
    "                        criterion=criterion_lora1,\n",
    "                        num_epochs=epochs)\n",
    "    \n",
    "    return lora_model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"8C3061\" >**Full Fine-Tunning (Bajo todos los Parámetros)**</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargar el modelo guardado only_encoder_model_crypto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2, Loss: 0.011290919409865248\n",
      "Epoch 2/2, Loss: 0.007608411135151982\n"
     ]
    }
   ],
   "source": [
    "load_model_to_complete_ft = ForecastingModel(seq_len=95,\n",
    "                                    pred_len=5,\n",
    "                                    embed_size=d_model,\n",
    "                                    nhead=nhead,\n",
    "                                    dim_feedforward=dim_feedforward,\n",
    "                                    dropout=dropout,\n",
    "                                    conv1d_emb=True,\n",
    "                                    conv1d_kernel_size=3,\n",
    "                                    device=device).to(device)\n",
    "\n",
    "load_model_to_complete_ft = load_model(load_model_to_complete_ft, \"only_encoder_model_crypto\")\n",
    "\n",
    "criterion_complete_ft = torch.nn.MSELoss()\n",
    "optimizer_complete_ft = torch.optim.Adam(load_model_to_complete_ft.parameters(), lr=0.0001)\n",
    "\n",
    "# Fine-tune for 2 epochs on the train_loader_exchange\n",
    "train_only_encoder(model=load_model_to_complete_ft, \n",
    "                       dataloader=train_loader_exchange, \n",
    "                       optimizer=optimizer_complete_ft, \n",
    "                       criterion=criterion_complete_ft, \n",
    "                       num_epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only Encoder Crypto score after fine-tuning:\n",
      "MSE: 0.010599355213344097\n",
      "MAE: 0.08186305314302444\n",
      "R2: 0.8700926899909973\n",
      "Trainable Parameters:  15923909\n"
     ]
    }
   ],
   "source": [
    "mse, mae, r2 = test_evaluation(load_model_to_complete_ft, test_loader_exchange)\n",
    "num_par = count_trainable_parameters(load_model_to_complete_ft)\n",
    "score.loc[2] = [\"OE_full_fine_tuning\", mse, mae, r2,num_par]\n",
    "print(\"Only Encoder Crypto score after fine-tuning:\\nMSE: {}\\nMAE: {}\\nR2: {}\".format(mse, mae, r2))\n",
    "print(\"Trainable Parameters: \", num_par)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model only_encoder_model_crypto_complete_ft already exists\n"
     ]
    }
   ],
   "source": [
    "save_model(load_model_to_complete_ft, \"only_encoder_model_crypto_complete_ft\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"8C3061\" >**Fine-Tunning (LoRA $r=1$)**</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters before fine-tuning:\t15,923,909\n",
      "Total parameters after fine-tuning:\t24,256\n",
      "\n",
      "\n",
      "Epoch 1/2, Loss: 0.006881394132506102\n",
      "Epoch 2/2, Loss: 0.0066655989503487945\n"
     ]
    }
   ],
   "source": [
    "lora_model_1 = LoRAModel(r = 1, epochs = 2)\n",
    "\n",
    "mse, mae, r2 = test_evaluation(lora_model_1, test_loader_crypto)\n",
    "num_par = count_trainable_parameters(lora_model_1)\n",
    "score.loc[3] = [\"LoRA r=1\", mse, mae, r2, num_par]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"8C3061\" >**Fine-Tunning (LoRA $r=2$)**</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters before fine-tuning:\t15,923,909\n",
      "Total parameters after fine-tuning:\t48,512\n",
      "\n",
      "\n",
      "Epoch 1/2, Loss: 0.00670599882557456\n",
      "Epoch 2/2, Loss: 0.006552244145755789\n"
     ]
    }
   ],
   "source": [
    "lora_model_2 = LoRAModel(r = 2, epochs = 2)\n",
    "\n",
    "mse, mae, r2 = test_evaluation(lora_model_2, test_loader_crypto)\n",
    "num_par = count_trainable_parameters(lora_model_2)\n",
    "score.loc[4] = [\"LoRA r=2\", mse, mae, r2, num_par]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"8C3061\" >**Fine-Tunning (LoRA $r=5$)**</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters before fine-tuning:\t15,923,909\n",
      "Total parameters after fine-tuning:\t121,280\n",
      "\n",
      "\n",
      "Epoch 1/2, Loss: 0.006792780569022787\n",
      "Epoch 2/2, Loss: 0.006537294913349407\n"
     ]
    }
   ],
   "source": [
    "lora_model_3 = LoRAModel(r = 5, epochs = 2)\n",
    "\n",
    "mse, mae, r2 = test_evaluation(lora_model_3, test_loader_crypto)\n",
    "num_par = count_trainable_parameters(lora_model_3)\n",
    "score.loc[5] = [\"LoRA r=5\", mse, mae, r2, num_par]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"8C3061\" >**Inferencia Sobre el Peso Mexicano**</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = scalers_cd['MXN']\n",
    "def dnorm(y_close,scaler=scaler):\n",
    "    place_holder = np.zeros((5,5))\n",
    "    place_holder[:,3] = y_close\n",
    "    return scaler.inverse_transform(place_holder)[:,3]\n",
    "\n",
    "def inference(model,data_loader,currency = 'MXN'):\n",
    "    \n",
    "    predicted_close_values = []\n",
    "    true_close_values = []\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in data_loader:\n",
    "            x_batch = x_batch.to(device).float()\n",
    "            y_batch = y_batch.to(device).float()\n",
    "            \n",
    "            output = model(x= x_batch)\n",
    "            \n",
    "            predicted_close_values.extend(output.cpu().numpy())\n",
    "            true_close_values.extend(y_batch.cpu().numpy())\n",
    "            \n",
    "    true_close_values = np.array(true_close_values)\n",
    "    predicted_close_values = np.array(predicted_close_values)\n",
    "\n",
    "    return dnorm(true_close_values),dnorm(predicted_close_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataMXN = exchange_data[exchange_data['Asset'] == 'MXN'].iloc[-100:,:].reset_index(drop=True)\n",
    "\n",
    "data = scalers_ed['MXN'].transform(dataMXN[['Open','High','Low','Close','Volume']])\n",
    "x, y = data[:95,:],data[-5:,3]\n",
    "\n",
    "inf_loader = gd.DataLoader_data(data=[(x,y)],batch_size=1)\n",
    "\n",
    "inf_only_enc =  inference(only_encoder_model_exchange, inf_loader, currency='MXN')\n",
    "inf_full_ft =   inference(load_model_to_complete_ft, inf_loader, currency='MXN')\n",
    "inf_lora_1 =    inference(lora_model_1, inf_loader, currency='MXN')\n",
    "inf_lora_2 =    inference(lora_model_2, inf_loader, currency='MXN')\n",
    "inf_lora_3 =    inference(lora_model_3, inf_loader, currency='MXN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "line": {
          "color": "blue"
         },
         "mode": "lines+markers",
         "name": "True Close",
         "type": "scatter",
         "x": [
          "2024-10-15 21:00:00+01:00",
          "2024-10-15 22:00:00+01:00",
          "2024-10-15 23:00:00+01:00",
          "2024-10-16 00:00:00+01:00",
          "2024-10-16 01:00:00+01:00"
         ],
         "y": [
          19.687530517578125,
          19.700000762939453,
          19.684999465942383,
          19.70400047302246,
          19.701000213623047
         ]
        },
        {
         "line": {
          "color": "red"
         },
         "mode": "lines+markers",
         "name": "Only Encoder Exchange",
         "type": "scatter",
         "x": [
          "2024-10-15 21:00:00+01:00",
          "2024-10-15 22:00:00+01:00",
          "2024-10-15 23:00:00+01:00",
          "2024-10-16 00:00:00+01:00",
          "2024-10-16 01:00:00+01:00"
         ],
         "y": [
          19.556647892115162,
          19.51130898486917,
          19.522483937937974,
          19.525265235015464,
          19.49787335378903
         ]
        },
        {
         "line": {
          "color": "green"
         },
         "mode": "lines+markers",
         "name": "Only Encoder Exchange Full Fine-Tuning",
         "type": "scatter",
         "x": [
          "2024-10-15 21:00:00+01:00",
          "2024-10-15 22:00:00+01:00",
          "2024-10-15 23:00:00+01:00",
          "2024-10-16 00:00:00+01:00",
          "2024-10-16 01:00:00+01:00"
         ],
         "y": [
          19.518492592859953,
          19.514166718014163,
          19.503670541619268,
          19.499626748388547,
          19.496879278336674
         ]
        },
        {
         "line": {
          "color": "purple"
         },
         "mode": "lines+markers",
         "name": "LoRA r=1",
         "type": "scatter",
         "x": [
          "2024-10-15 21:00:00+01:00",
          "2024-10-15 22:00:00+01:00",
          "2024-10-15 23:00:00+01:00",
          "2024-10-16 00:00:00+01:00",
          "2024-10-16 01:00:00+01:00"
         ],
         "y": [
          19.546882290027153,
          19.53437682083654,
          19.5239273192318,
          19.523889955005185,
          19.494036588460286
         ]
        },
        {
         "line": {
          "color": "orange"
         },
         "mode": "lines+markers",
         "name": "LoRA r=2",
         "type": "scatter",
         "x": [
          "2024-10-15 21:00:00+01:00",
          "2024-10-15 22:00:00+01:00",
          "2024-10-15 23:00:00+01:00",
          "2024-10-16 00:00:00+01:00",
          "2024-10-16 01:00:00+01:00"
         ],
         "y": [
          19.543262635656102,
          19.535209120165174,
          19.52250349418716,
          19.52406022854279,
          19.49314253041541
         ]
        },
        {
         "line": {
          "color": "black"
         },
         "mode": "lines+markers",
         "name": "LoRA r=5",
         "type": "scatter",
         "x": [
          "2024-10-15 21:00:00+01:00",
          "2024-10-15 22:00:00+01:00",
          "2024-10-15 23:00:00+01:00",
          "2024-10-16 00:00:00+01:00",
          "2024-10-16 01:00:00+01:00"
         ],
         "y": [
          19.55311691171391,
          19.545509774725698,
          19.5325185705891,
          19.535326335687838,
          19.505071720446036
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Comparison of the different models for the MXN currency"
        },
        "xaxis": {
         "rangeslider": {
          "visible": false
         },
         "title": {
          "text": "Datetime"
         }
        },
        "yaxis": {
         "title": {
          "text": "Close"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "# Add traces\n",
    "fig.add_trace(go.Scatter(x = dataMXN['Datetime'].iloc[-5:], y = dataMXN['Close'].iloc[-5:], mode='lines+markers', name='True Close',line=dict(color='blue')))\n",
    "fig.add_trace(go.Scatter(x = dataMXN['Datetime'].iloc[-5:], y = inf_only_enc[1], mode='lines+markers', name='Only Encoder Exchange',line=dict(color='red')))\n",
    "fig.add_trace(go.Scatter(x = dataMXN['Datetime'].iloc[-5:], y = inf_full_ft[1], mode='lines+markers', name='Only Encoder Exchange Full Fine-Tuning',line=dict(color='green')))\n",
    "fig.add_trace(go.Scatter(x = dataMXN['Datetime'].iloc[-5:], y = inf_lora_1[1], mode='lines+markers', name='LoRA r=1',line=dict(color='purple')))\n",
    "fig.add_trace(go.Scatter(x = dataMXN['Datetime'].iloc[-5:], y = inf_lora_2[1], mode='lines+markers', name='LoRA r=2',line=dict(color='orange')))\n",
    "fig.add_trace(go.Scatter(x = dataMXN['Datetime'].iloc[-5:], y = inf_lora_3[1], mode='lines+markers', name='LoRA r=5',line=dict(color='black')))\n",
    "\n",
    "fig.update_layout(title='Comparison of the different models for the MXN currency',\n",
    "                     xaxis_title='Datetime',\n",
    "                     yaxis_title='Close',\n",
    "                     xaxis_rangeslider_visible=False)\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"8C3061\" >**Conclusiones**</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Entre los modelos implementados el que tuvo mejor desempeño fue el que se le realizó un fine-tuning con LoRA (r=1)\n",
    "> - Se reentreno tan solo $24256$ parámetros en el modelo LoRA (r=1)\n",
    "> - El modelo con peor rendimiento fue el que se realizó un tuning a partir de todos  los modelos.\n",
    "> - Las inferencias sobre la moneda MXN resultan considerablemente buenas.\n",
    "> - El entrenamiento del modelo only_encoder_transformer con los datos del cambio de la moneda solo superó al full_tuning del modelo de las cryptomonedas en desempeño."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "      <th>Trainable Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LoRA r=1</td>\n",
       "      <td>0.009067</td>\n",
       "      <td>0.071250</td>\n",
       "      <td>0.888840</td>\n",
       "      <td>24256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LoRA r=2</td>\n",
       "      <td>0.009139</td>\n",
       "      <td>0.071598</td>\n",
       "      <td>0.887974</td>\n",
       "      <td>48512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LoRA r=5</td>\n",
       "      <td>0.009167</td>\n",
       "      <td>0.071385</td>\n",
       "      <td>0.887663</td>\n",
       "      <td>121280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Only Encoder Exchange</td>\n",
       "      <td>0.009579</td>\n",
       "      <td>0.074044</td>\n",
       "      <td>0.882640</td>\n",
       "      <td>15923909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OE_full_fine_tuning</td>\n",
       "      <td>0.010599</td>\n",
       "      <td>0.081863</td>\n",
       "      <td>0.870093</td>\n",
       "      <td>15923909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model       MSE       MAE        R2  Trainable Parameters\n",
       "0               LoRA r=1  0.009067  0.071250  0.888840                 24256\n",
       "1               LoRA r=2  0.009139  0.071598  0.887974                 48512\n",
       "2               LoRA r=5  0.009167  0.071385  0.887663                121280\n",
       "3  Only Encoder Exchange  0.009579  0.074044  0.882640              15923909\n",
       "4    OE_full_fine_tuning  0.010599  0.081863  0.870093              15923909"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(score.iloc[[0,2,3,4,5]].sort_values(by='MSE').reset_index(drop=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
